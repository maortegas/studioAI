import { ProjectRepository } from '../repositories/projectRepository';
import { ReleaseRepository } from '../repositories/releaseRepository';
import { ensureDirectory, createFile } from '../utils/fileSystem';
import path from 'path';
import fs from 'fs/promises';

export type DeploymentEnvironment = 'staging' | 'production';

export interface DeploymentConfig {
  environment: DeploymentEnvironment;
  release_id?: string;
  version?: string;
  database_url?: string;
  api_port?: number;
  frontend_port?: number;
  node_env?: string;
}

export class DeploymentService {
  private projectRepo: ProjectRepository;
  private releaseRepo: ReleaseRepository;

  constructor() {
    this.projectRepo = new ProjectRepository();
    this.releaseRepo = new ReleaseRepository();
  }

  /**
   * Generate deployment package for staging or production
   */
  async generateDeployment(projectId: string, config: DeploymentConfig): Promise<{
    docker_compose_path: string;
    readme_path: string;
    package_json_path: string;
    env_example_path: string;
  }> {
    const project = await this.projectRepo.findById(projectId);
    if (!project) {
      throw new Error('Project not found');
    }

    // Validate and prepare project structure
    await this.validateAndPrepareStructure(project.base_path, project.tech_stack);

    // Get release info if provided
    let release = null;
    if (config.release_id) {
      release = await this.releaseRepo.findById(config.release_id);
    }

    // Generate docker-compose
    const dockerComposePath = await this.generateDockerCompose(
      project.base_path,
      project,
      config,
      release
    );

    // Generate README
    const readmePath = await this.generateREADME(
      project.base_path,
      project,
      config,
      release
    );

    // Generate .env.example
    const envExamplePath = await this.generateEnvExample(
      project.base_path,
      config
    );

    // Generate Dockerfiles
    const dockerfileBackendPath = await this.generateDockerfileBackend(
      project.base_path,
      project
    );
    const dockerfileFrontendPath = await this.generateDockerfileFrontend(
      project.base_path,
      project
    );

    return {
      docker_compose_path: dockerComposePath,
      readme_path: readmePath,
      package_json_path: path.join(project.base_path, 'package.json'),
      env_example_path: envExamplePath,
      dockerfile_backend_path: dockerfileBackendPath,
      dockerfile_frontend_path: dockerfileFrontendPath,
    };
  }

  /**
   * Validate and prepare project structure
   */
  private async validateAndPrepareStructure(
    basePath: string,
    techStack?: string
  ): Promise<void> {
    // Check if package.json exists, create if not
    const packageJsonPath = path.join(basePath, 'package.json');
    try {
      await fs.access(packageJsonPath);
    } catch {
      // package.json doesn't exist, create it
      await this.createPackageJson(packageJsonPath, techStack);
    }

    // Ensure .env.example exists (will be created by generateEnvExample)
    // Ensure README.md exists (will be created by generateREADME)
  }

  /**
   * Create package.json if it doesn't exist
   */
  private async createPackageJson(
    packageJsonPath: string,
    techStack?: string
  ): Promise<void> {
    const packageJson = {
      name: path.basename(path.dirname(packageJsonPath)),
      version: '1.0.0',
      description: 'Generated by DevFlow Studio',
      private: true,
      scripts: {
        start: 'node dist/index.js',
        build: 'tsc',
        dev: 'tsx watch src/index.ts',
        test: 'echo "Error: no test specified" && exit 1',
      },
      dependencies: {},
      devDependencies: {
        '@types/node': '^20.10.0',
        typescript: '^5.3.3',
        tsx: '^4.7.0',
      },
      engines: {
        node: '>=18.0.0',
      },
    };

    // Add dependencies based on tech stack
    if (techStack) {
      const stack = techStack.toLowerCase();
      if (stack.includes('express')) {
        packageJson.dependencies = {
          ...packageJson.dependencies,
          express: '^4.18.2',
          cors: '^2.8.5',
          dotenv: '^17.2.3',
        };
        packageJson.devDependencies = {
          ...packageJson.devDependencies,
          '@types/express': '^4.17.21',
          '@types/cors': '^2.8.17',
        };
      }
      if (stack.includes('react')) {
        packageJson.dependencies = {
          ...packageJson.dependencies,
          react: '^18.2.0',
          'react-dom': '^18.2.0',
        };
        packageJson.devDependencies = {
          ...packageJson.devDependencies,
          '@types/react': '^18.2.0',
          '@types/react-dom': '^18.2.0',
        };
      }
      if (stack.includes('postgres') || stack.includes('postgresql')) {
        packageJson.dependencies = {
          ...packageJson.dependencies,
          pg: '^8.11.3',
        };
        packageJson.devDependencies = {
          ...packageJson.devDependencies,
          '@types/pg': '^8.10.9',
        };
      }
    }

    await createFile(packageJsonPath, JSON.stringify(packageJson, null, 2));
  }

  /**
   * Generate docker-compose.yml for deployment
   */
  private async generateDockerCompose(
    basePath: string,
    project: any,
    config: DeploymentConfig,
    release: any
  ): Promise<string> {
    const env = config.environment;
    const apiPort = config.api_port || (env === 'production' ? 3000 : 3001);
    const frontendPort = config.frontend_port || (env === 'production' ? 80 : 8080);
    const dbPort = env === 'production' ? 5432 : 5433; // Different port for staging

    const dockerCompose = `version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    container_name: ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-postgres
    environment:
      POSTGRES_USER: \${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: \${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: \${POSTGRES_DB:-${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}}
    ports:
      - "${dbPort}:5432"
    volumes:
      - postgres_data_${env}:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U \${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: ${env === 'production' ? 'always' : 'unless-stopped'}
    networks:
      - ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-network

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-backend
    environment:
      NODE_ENV: ${config.node_env || (env === 'production' ? 'production' : 'staging')}
      DATABASE_URL: postgresql://\${POSTGRES_USER:-postgres}:\${POSTGRES_PASSWORD:-postgres}@postgres:5432/\${POSTGRES_DB:-${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}}
      PORT: ${apiPort}
      API_PORT: ${apiPort}
    ports:
      - "${apiPort}:${apiPort}"
    depends_on:
      postgres:
        condition: service_healthy
    restart: ${env === 'production' ? 'always' : 'unless-stopped'}
    networks:
      - ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-network
    volumes:
      - ./uploads:/app/uploads
    ${env === 'production' ? 'logging:\n      driver: "json-file"\n      options:\n        max-size: "10m"\n        max-file: "3"' : ''}

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-frontend
    environment:
      NODE_ENV: ${config.node_env || (env === 'production' ? 'production' : 'staging')}
      REACT_APP_API_URL: \${REACT_APP_API_URL:-http://localhost:${apiPort}}
    ports:
      - "${frontendPort}:80"
    depends_on:
      - backend
    restart: ${env === 'production' ? 'always' : 'unless-stopped'}
    networks:
      - ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-network
    ${env === 'production' ? 'logging:\n      driver: "json-file"\n      options:\n        max-size: "10m"\n        max-file: "3"' : ''}

volumes:
  postgres_data_${env}:
    driver: local

networks:
  ${project.name.toLowerCase().replace(/\s+/g, '-')}-${env}-network:
    driver: bridge
`;

    const dockerComposePath = path.join(
      basePath,
      `docker-compose.${env}.yml`
    );
    await createFile(dockerComposePath, dockerCompose);
    return dockerComposePath;
  }

  /**
   * Generate comprehensive README.md
   */
  private async generateREADME(
    basePath: string,
    project: any,
    config: DeploymentConfig,
    release: any
  ): Promise<string> {
    const env = config.environment;
    const apiPort = config.api_port || (env === 'production' ? 3000 : 3001);
    const frontendPort = config.frontend_port || (env === 'production' ? 80 : 8080);
    const dbPort = env === 'production' ? 5432 : 5433;

    const readme = `# ${project.name} - ${env.charAt(0).toUpperCase() + env.slice(1)} Deployment

${release ? `**Release Version:** ${release.version}\n**Release Date:** ${release.release_date ? new Date(release.release_date).toLocaleDateString() : 'N/A'}` : ''}

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Configuration](#configuration)
- [Database Setup](#database-setup)
- [Running the Application](#running-the-application)
- [Troubleshooting](#troubleshooting)
- [Maintenance](#maintenance)

## Overview

This is the ${env} deployment configuration for ${project.name}.

**Tech Stack:** ${project.tech_stack || 'Not specified'}

## Prerequisites

Before deploying, ensure you have:

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Node.js** >= 18.0.0 (for local development)
- **PostgreSQL** client tools (optional, for direct DB access)

## Quick Start

1. **Clone and navigate to the project:**
   \`\`\`bash
   cd ${path.basename(basePath)}
   \`\`\`

2. **Copy environment variables:**
   \`\`\`bash
   cp .env.example .env
   \`\`\`

3. **Edit .env file** with your configuration (see [Configuration](#configuration))

4. **Start all services:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml up -d
   \`\`\`

5. **Check service status:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml ps
   \`\`\`

6. **View logs:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml logs -f
   \`\`\`

## Configuration

### Environment Variables

Create a \`.env\` file in the project root with the following variables:

\`\`\`env
# Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}

# Backend Configuration
NODE_ENV=${env}
API_PORT=${apiPort}
DATABASE_URL=postgresql://postgres:your_secure_password_here@postgres:5432/${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}

# Frontend Configuration
REACT_APP_API_URL=http://localhost:${apiPort}
\`\`\`

### Port Configuration

- **Frontend:** http://localhost:${frontendPort}
- **Backend API:** http://localhost:${apiPort}
- **PostgreSQL:** localhost:${dbPort}

${env === 'production' ? '**âš ï¸ Production Note:** Change default passwords and use secure environment variables!' : ''}

## Database Setup

### Initial Setup

The database is automatically initialized when you start the services. The PostgreSQL container will:

1. Create the database if it doesn't exist
2. Run migrations (if configured)
3. Set up initial schema

### Accessing the Database

**Using Docker:**
\`\`\`bash
docker-compose -f docker-compose.${env}.yml exec postgres psql -U postgres -d ${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}
\`\`\`

**Using psql client:**
\`\`\`bash
psql -h localhost -p ${dbPort} -U postgres -d ${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}
\`\`\`

**Connection String:**
\`\`\`
postgresql://postgres:your_password@localhost:${dbPort}/${project.name.toLowerCase().replace(/\s+/g, '_')}_${env}
\`\`\`

### Database Migrations

If your project uses migrations, run them after the database is up:

\`\`\`bash
# Example: Run migrations
npm run migrate
# or
docker-compose -f docker-compose.${env}.yml exec backend npm run migrate
\`\`\`

## Running the Application

### Start Services

\`\`\`bash
docker-compose -f docker-compose.${env}.yml up -d
\`\`\`

### Stop Services

\`\`\`bash
docker-compose -f docker-compose.${env}.yml down
\`\`\`

### Restart Services

\`\`\`bash
docker-compose -f docker-compose.${env}.yml restart
\`\`\`

### View Logs

**All services:**
\`\`\`bash
docker-compose -f docker-compose.${env}.yml logs -f
\`\`\`

**Specific service:**
\`\`\`bash
docker-compose -f docker-compose.${env}.yml logs -f backend
docker-compose -f docker-compose.${env}.yml logs -f frontend
docker-compose -f docker-compose.${env}.yml logs -f postgres
\`\`\`

### Rebuild Services

\`\`\`bash
docker-compose -f docker-compose.${env}.yml build --no-cache
docker-compose -f docker-compose.${env}.yml up -d
\`\`\`

## Troubleshooting

### Services won't start

1. **Check Docker is running:**
   \`\`\`bash
   docker ps
   \`\`\`

2. **Check port availability:**
   \`\`\`bash
   # Check if ports are in use
   lsof -i :${apiPort}
   lsof -i :${frontendPort}
   lsof -i :${dbPort}
   \`\`\`

3. **View error logs:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml logs
   \`\`\`

### Database connection issues

1. **Verify database is healthy:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml ps postgres
   \`\`\`

2. **Check database logs:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml logs postgres
   \`\`\`

3. **Test connection:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml exec postgres pg_isready -U postgres
   \`\`\`

### Frontend can't connect to backend

1. **Verify backend is running:**
   \`\`\`bash
   curl http://localhost:${apiPort}/health
   \`\`\`

2. **Check REACT_APP_API_URL in .env:**
   \`\`\`bash
   grep REACT_APP_API_URL .env
   \`\`\`

3. **Check network connectivity:**
   \`\`\`bash
   docker-compose -f docker-compose.${env}.yml exec frontend ping backend
   \`\`\`

## Maintenance

### Backup Database

\`\`\`bash
docker-compose -f docker-compose.${env}.yml exec postgres pg_dump -U postgres ${project.name.toLowerCase().replace(/\s+/g, '_')}_${env} > backup_$(date +%Y%m%d_%H%M%S).sql
\`\`\`

### Restore Database

\`\`\`bash
docker-compose -f docker-compose.${env}.yml exec -T postgres psql -U postgres ${project.name.toLowerCase().replace(/\s+/g, '_')}_${env} < backup_file.sql
\`\`\`

### Clean Up

**Remove containers and volumes:**
\`\`\`bash
docker-compose -f docker-compose.${env}.yml down -v
\`\`\`

**Remove images:**
\`\`\`bash
docker-compose -f docker-compose.${env}.yml down --rmi all
\`\`\`

---

**Generated by DevFlow Studio** - ${new Date().toLocaleDateString()}
${release ? `\n**Release:** ${release.version}` : ''}
`;

    const readmePath = path.join(basePath, `README.${env}.md`);
    await createFile(readmePath, readme);
    return readmePath;
  }

  /**
   * Generate .env.example file
   */
  private async generateEnvExample(
    basePath: string,
    config: DeploymentConfig
  ): Promise<string> {
    const env = config.environment;
    const apiPort = config.api_port || (env === 'production' ? 3000 : 3001);

    const envExample = `# ${env.charAt(0).toUpperCase() + env.slice(1)} Environment Configuration

# Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=change_this_secure_password
POSTGRES_DB=app_${env}

# Backend Configuration
NODE_ENV=${env}
API_PORT=${apiPort}
DATABASE_URL=postgresql://postgres:change_this_secure_password@postgres:5432/app_${env}

# Frontend Configuration
REACT_APP_API_URL=http://localhost:${apiPort}

# Additional Configuration
# Add your custom environment variables here
`;

    const envExamplePath = path.join(basePath, '.env.example');
    await createFile(envExamplePath, envExample);
    return envExamplePath;
  }

  /**
   * Generate Dockerfile for backend
   */
  private async generateDockerfileBackend(
    basePath: string,
    project: any
  ): Promise<string> {
    const dockerfile = `# Backend Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
COPY packages/backend/package*.json ./packages/backend/
COPY packages/shared/package*.json ./packages/shared/

# Install dependencies
RUN npm ci --workspace=packages/backend --workspace=packages/shared

# Copy source code
COPY packages/backend ./packages/backend
COPY packages/shared ./packages/shared

# Build
WORKDIR /app/packages/backend
RUN npm run build

# Production image
FROM node:18-alpine

WORKDIR /app

# Copy built files
COPY --from=builder /app/packages/backend/dist ./dist
COPY --from=builder /app/packages/backend/package.json ./
COPY --from=builder /app/packages/shared/dist ./node_modules/@devflow-studio/shared
COPY --from=builder /app/node_modules ./node_modules

# Create uploads directory
RUN mkdir -p /app/uploads

# Expose port
EXPOSE 3000

# Start application
CMD ["node", "dist/server.js"]
`;

    const dockerfilePath = path.join(basePath, 'Dockerfile.backend');
    await createFile(dockerfilePath, dockerfile);
    return dockerfilePath;
  }

  /**
   * Generate Dockerfile for frontend
   */
  private async generateDockerfileFrontend(
    basePath: string,
    project: any
  ): Promise<string> {
    const dockerfile = `# Frontend Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
COPY packages/frontend/package*.json ./packages/frontend/
COPY packages/shared/package*.json ./packages/shared/

# Install dependencies
RUN npm ci --workspace=packages/frontend --workspace=packages/shared

# Copy source code
COPY packages/frontend ./packages/frontend
COPY packages/shared ./packages/shared

# Build
WORKDIR /app/packages/frontend
RUN npm run build

# Production image with nginx
FROM nginx:alpine

# Copy built files
COPY --from=builder /app/packages/frontend/dist /usr/share/nginx/html

# Copy nginx configuration
RUN echo 'server { \\
    listen 80; \\
    server_name localhost; \\
    root /usr/share/nginx/html; \\
    index index.html; \\
    location / { \\
        try_files $uri $uri/ /index.html; \\
    } \\
    location /api { \\
        proxy_pass http://backend:3000; \\
        proxy_http_version 1.1; \\
        proxy_set_header Upgrade $http_upgrade; \\
        proxy_set_header Connection "upgrade"; \\
        proxy_set_header Host $host; \\
        proxy_set_header X-Real-IP $remote_addr; \\
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; \\
        proxy_set_header X-Forwarded-Proto $scheme; \\
    } \\
}' > /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
`;

    const dockerfilePath = path.join(basePath, 'Dockerfile.frontend');
    await createFile(dockerfilePath, dockerfile);
    return dockerfilePath;
  }
}

